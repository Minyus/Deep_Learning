{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_fit_with_callbacks_cifar10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vRgMOgH-ajJW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up Google Colab environment"
      ]
    },
    {
      "metadata": {
        "id": "7F29nuHfiiUA",
        "colab_type": "code",
        "outputId": "f3e51bfc-d0c7-43a8-f0f6-a5b4d0a87620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "### Set colaboratory True to run in Google Colaboratory. \n",
        "colab = True\n",
        "\n",
        "if colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  import os\n",
        "  ## Specify a directory in Google Drive\n",
        "  dir = '/content/drive/My Drive/Colab Notebooks/Save_Restore_Model'\n",
        "  os.chdir(dir)\n",
        "  #os.getcwd()\n",
        "  #os.listdir()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "As19XFC8jE-g",
        "colab_type": "code",
        "outputId": "dc7ead9c-f986-46cd-a7ec-a8d40156e4a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "cell_type": "code",
      "source": [
        "if colab:\n",
        "  ## Check the uptime. (Google Colab reboots every 12 hours)\n",
        "  !cat /proc/uptime | awk '{print \"Uptime is \" $1 /60 /60 \" hours (\" $1 \" sec)\"}'\n",
        "  ## Check the GPU info\n",
        "  !nvidia-smi\n",
        "  ## Check the Python version\n",
        "  !python --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uptime is 0.0302694 hours (108.97 sec)\n",
            "Fri Jan 25 13:19:10 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Python 3.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KN-GFrsvarFB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import modules"
      ]
    },
    {
      "metadata": {
        "id": "HZ219oTUjJXf",
        "colab_type": "code",
        "outputId": "0a52161f-bee1-44c7-a2f7-c0ad5378f9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "t6bn6IwDfK8b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56ee8c7b-b2d4-403e-c11c-9826a330fde8"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MpoVWvOdxUgf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up data"
      ]
    },
    {
      "metadata": {
        "id": "Y3mzIuRfevKm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4e9cef80-efc7-4e0a-a5bc-f49d7db25d8c"
      },
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 94s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i56U6WpKhKE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e50310fa-1098-49f5-9220-d16a699482f4"
      },
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "kev1iTmohPvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "ff6690f3-b8c1-4db5-ee32-e0a7e075fb73"
      },
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "feKRA_oSffMa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "# Convert class vectors to binary class matrices.\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-_Hx-CTbgthc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "train_images /= 255\n",
        "test_images /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q95svqIyiguC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape = train_images.shape[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ciSTm1zha2ki",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define model"
      ]
    },
    {
      "metadata": {
        "id": "k8pNftRxLT1i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Returns a short sequential model\n",
        "def create_model(input_shape):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                   input_shape=input_shape))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  # initiate RMSprop optimizer\n",
        "  opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "  # Let's train the model using RMSprop\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwFUcdCfa4Vs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fit model"
      ]
    },
    {
      "metadata": {
        "id": "jrXvLv4kjx-v",
        "colab_type": "code",
        "outputId": "e64e58cc-4a05-491b-81d7-14e068511a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2610
        }
      },
      "cell_type": "code",
      "source": [
        "### If resume_if_possible = True, fitting can resume using a model file. \n",
        "resume_if_possible = True \n",
        "\n",
        "### Set resume_if_possible = False to force fitting from scratch.\n",
        "#resume_if_possible = False \n",
        "\n",
        "epochs = 100\n",
        "log_file_path = 'training_log.csv'\n",
        "model_file_path = 'model_epoch{epoch:06d}.hdf5'\n",
        "\n",
        "model_file_list = glob.glob('model_epoch*.hdf5')\n",
        "log_file_list = glob.glob(log_file_path)\n",
        "\n",
        "if resume_if_possible:\n",
        "  resume_flag = (len(model_file_list) >= 1) \n",
        "  \n",
        "if not resume_if_possible:\n",
        "  resume_flag = False\n",
        "  for f in model_file_list:\n",
        "    os.remove(f)\n",
        "\n",
        "if resume_flag:\n",
        "  latest_model_file = model_file_list[-1]\n",
        "  latest_epoch = int(latest_model_file[len('model_epoch'):-len('.hdf5')])\n",
        "  ## Load the saved model\n",
        "  model = keras.models.load_model(latest_model_file)\n",
        "\n",
        "  score = model.evaluate(test_images,test_labels, verbose=0)\n",
        "  print('Use {} to resume fitting. \\nTest loss: {}   Test accuracy: {}'.format(latest_model_file, score[0], score[1]))\n",
        "\n",
        "  if len(model_file_list) >= 2:\n",
        "    ## Delete all model files excpet the latest to save space\n",
        "    for f in model_file_list[:-1]:\n",
        "      os.remove(f)\n",
        "\n",
        "if not resume_flag:\n",
        "  latest_epoch = 0\n",
        "  ## Create a basic model instance\n",
        "  model = create_model(input_shape)\n",
        "  for f in log_file_list:\n",
        "    os.remove(f)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "## Create checkpoint callback\n",
        "check_point_ = tf.keras.callbacks.ModelCheckpoint(filepath = model_file_path, \n",
        "                                                 monitor = 'val_acc',\n",
        "                                                 verbose=1,\n",
        "                                                 save_best_only = True,\n",
        "                                                 mode='auto',\n",
        "                                                 save_weights_only=False,\n",
        "                                                 period = 1)\n",
        "\n",
        "## Create early stopping callback\n",
        "early_stopping_ = tf.keras.callbacks.EarlyStopping(monitor='val_acc', \n",
        "                                                   min_delta=0, \n",
        "                                                   patience=3, \n",
        "                                                   verbose=1, \n",
        "                                                   mode='auto', \n",
        "                                                   baseline=None)\n",
        "\n",
        "## Create CSV logger callback\n",
        "csv_logger_ = tf.keras.callbacks.CSVLogger(filename = log_file_path, separator=',',\n",
        "                                           append = resume_flag)\n",
        "\n",
        "## Fit \n",
        "model.fit(train_images, train_labels, epochs = epochs, initial_epoch = latest_epoch,\n",
        "          validation_data = (test_images,test_labels), shuffle = True,\n",
        "          callbacks = [check_point_, early_stopping_, csv_logger_])\n",
        "\n",
        "## Remove duplicates as save_best_only option of checkpoint is set to True.\n",
        "pd.options.display.max_rows = 8\n",
        "log_df = pd.read_csv(log_file_path)\n",
        "log_wo_dup_df = log_df.drop_duplicates(subset = ['epoch'], keep='last').reset_index(drop=True)\n",
        "display(log_wo_dup_df)\n",
        "log_wo_dup_df.to_csv((log_file_path[:-len('.csv')] + '_processed.csv'), index=False)\n",
        "\n",
        "print('\\nFiles in the working directoy:')\n",
        "display(os.listdir())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 24s 477us/step - loss: 1.8008 - acc: 0.3392 - val_loss: 1.4961 - val_acc: 0.4579\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.45790, saving model to model_epoch000001.hdf5\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 20s 394us/step - loss: 1.4803 - acc: 0.4648 - val_loss: 1.4378 - val_acc: 0.4878\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.45790 to 0.48780, saving model to model_epoch000002.hdf5\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 20s 392us/step - loss: 1.3421 - acc: 0.5189 - val_loss: 1.3100 - val_acc: 0.5343\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.48780 to 0.53430, saving model to model_epoch000003.hdf5\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 20s 391us/step - loss: 1.2444 - acc: 0.5585 - val_loss: 1.2277 - val_acc: 0.5561\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.53430 to 0.55610, saving model to model_epoch000004.hdf5\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 19s 389us/step - loss: 1.1685 - acc: 0.5857 - val_loss: 1.1138 - val_acc: 0.6127\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.55610 to 0.61270, saving model to model_epoch000005.hdf5\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 19s 389us/step - loss: 1.1058 - acc: 0.6113 - val_loss: 1.0280 - val_acc: 0.6356\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.61270 to 0.63560, saving model to model_epoch000006.hdf5\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 20s 393us/step - loss: 1.0528 - acc: 0.6314 - val_loss: 1.0581 - val_acc: 0.6276\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.63560\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 20s 390us/step - loss: 1.0055 - acc: 0.6465 - val_loss: 0.9294 - val_acc: 0.6765\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.63560 to 0.67650, saving model to model_epoch000008.hdf5\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 20s 392us/step - loss: 0.9643 - acc: 0.6635 - val_loss: 0.9114 - val_acc: 0.6836\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.67650 to 0.68360, saving model to model_epoch000009.hdf5\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 20s 394us/step - loss: 0.9356 - acc: 0.6698 - val_loss: 0.8952 - val_acc: 0.6869\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.68360 to 0.68690, saving model to model_epoch000010.hdf5\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 20s 394us/step - loss: 0.9045 - acc: 0.6836 - val_loss: 0.8667 - val_acc: 0.7009\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.68690 to 0.70090, saving model to model_epoch000011.hdf5\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 20s 395us/step - loss: 0.8775 - acc: 0.6954 - val_loss: 0.8287 - val_acc: 0.7105\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.70090 to 0.71050, saving model to model_epoch000012.hdf5\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 20s 393us/step - loss: 0.8528 - acc: 0.7029 - val_loss: 0.8416 - val_acc: 0.7039\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.71050\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 19s 390us/step - loss: 0.8315 - acc: 0.7123 - val_loss: 0.8020 - val_acc: 0.7205\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.71050 to 0.72050, saving model to model_epoch000014.hdf5\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 19s 389us/step - loss: 0.8091 - acc: 0.7193 - val_loss: 0.7679 - val_acc: 0.7343\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.72050 to 0.73430, saving model to model_epoch000015.hdf5\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 19s 385us/step - loss: 0.7901 - acc: 0.7260 - val_loss: 0.8272 - val_acc: 0.7123\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.73430\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 19s 387us/step - loss: 0.7777 - acc: 0.7290 - val_loss: 0.7767 - val_acc: 0.7275\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.73430\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 19s 385us/step - loss: 0.7654 - acc: 0.7332 - val_loss: 0.7737 - val_acc: 0.7302\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.73430\n",
            "Epoch 00018: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>val_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.33920</td>\n",
              "      <td>1.800833</td>\n",
              "      <td>0.4579</td>\n",
              "      <td>1.496150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.46480</td>\n",
              "      <td>1.480331</td>\n",
              "      <td>0.4878</td>\n",
              "      <td>1.437762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.51890</td>\n",
              "      <td>1.342115</td>\n",
              "      <td>0.5343</td>\n",
              "      <td>1.310025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.55846</td>\n",
              "      <td>1.244442</td>\n",
              "      <td>0.5561</td>\n",
              "      <td>1.227676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>0.71932</td>\n",
              "      <td>0.809133</td>\n",
              "      <td>0.7343</td>\n",
              "      <td>0.767934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.72598</td>\n",
              "      <td>0.790149</td>\n",
              "      <td>0.7123</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>0.72898</td>\n",
              "      <td>0.777677</td>\n",
              "      <td>0.7275</td>\n",
              "      <td>0.776697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>0.73324</td>\n",
              "      <td>0.765359</td>\n",
              "      <td>0.7302</td>\n",
              "      <td>0.773748</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    epoch      acc      loss  val_acc  val_loss\n",
              "0       0  0.33920  1.800833   0.4579  1.496150\n",
              "1       1  0.46480  1.480331   0.4878  1.437762\n",
              "2       2  0.51890  1.342115   0.5343  1.310025\n",
              "3       3  0.55846  1.244442   0.5561  1.227676\n",
              "..    ...      ...       ...      ...       ...\n",
              "14     14  0.71932  0.809133   0.7343  0.767934\n",
              "15     15  0.72598  0.790149   0.7123  0.827213\n",
              "16     16  0.72898  0.777677   0.7275  0.776697\n",
              "17     17  0.73324  0.765359   0.7302  0.773748\n",
              "\n",
              "[18 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Files in the working directoy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['keras_fit_with_callbacks_cifar10.ipynb',\n",
              " 'training_log.csv',\n",
              " 'model_epoch000001.hdf5',\n",
              " 'model_epoch000002.hdf5',\n",
              " 'model_epoch000003.hdf5',\n",
              " 'model_epoch000004.hdf5',\n",
              " 'model_epoch000005.hdf5',\n",
              " 'model_epoch000006.hdf5',\n",
              " 'model_epoch000008.hdf5',\n",
              " 'model_epoch000009.hdf5',\n",
              " 'model_epoch000010.hdf5',\n",
              " 'model_epoch000011.hdf5',\n",
              " 'model_epoch000012.hdf5',\n",
              " 'model_epoch000014.hdf5',\n",
              " 'model_epoch000015.hdf5',\n",
              " 'training_log_processed.csv']"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "K8zre0uERDU2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "\n",
        "https://keras.io/callbacks/\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint"
      ]
    }
  ]
}