{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_fit_with_callbacks_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vRgMOgH-ajJW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up Google Colab environment"
      ]
    },
    {
      "metadata": {
        "id": "7F29nuHfiiUA",
        "colab_type": "code",
        "outputId": "adeb183a-8cbb-4c61-f514-4387e172cf48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "### Set colaboratory True to run in Google Colaboratory. \n",
        "colab = True\n",
        "\n",
        "if colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  import os\n",
        "  ## Specify a directory in Google Drive\n",
        "  dir = '/content/drive/My Drive/Colab Notebooks/Save_Restore_Model'\n",
        "  os.chdir(dir)\n",
        "  #os.getcwd()\n",
        "  #os.listdir()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "As19XFC8jE-g",
        "colab_type": "code",
        "outputId": "b3694132-828d-4204-8030-a194b6ca2c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "if colab:\n",
        "  ## Check the uptime. (Google Colab reboots every 12 hours)\n",
        "  !cat /proc/uptime | awk '{print \"Uptime is \" $1 /60 /60 \" hours (\" $1 \" sec)\"}'\n",
        "  ## Check the GPU info\n",
        "  !nvidia-smi\n",
        "  ## Check the Python version\n",
        "  !python --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uptime is 11.2148 hours (40373.35 sec)\n",
            "Fri Jan 25 09:59:32 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Python 3.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KN-GFrsvarFB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import modules"
      ]
    },
    {
      "metadata": {
        "id": "HZ219oTUjJXf",
        "colab_type": "code",
        "outputId": "8d2216e6-78ec-426b-e8dc-2a78410e5337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "MpoVWvOdxUgf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up data"
      ]
    },
    {
      "metadata": {
        "id": "65zkKSbQ3Jnc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_labels = train_labels[:1000]\n",
        "test_labels = test_labels[:1000]\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
        "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ciSTm1zha2ki",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define model"
      ]
    },
    {
      "metadata": {
        "id": "k8pNftRxLT1i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Returns a short sequential model\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    keras.layers.Dense(512, activation=tf.keras.activations.relu, input_shape=(784,)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
        "  ])\n",
        "  \n",
        "  model.compile(optimizer='adam', \n",
        "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwFUcdCfa4Vs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fit model"
      ]
    },
    {
      "metadata": {
        "id": "jrXvLv4kjx-v",
        "colab_type": "code",
        "outputId": "8306481b-ee8c-4d43-bbb9-3096f77b4851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        }
      },
      "cell_type": "code",
      "source": [
        "### If resume_if_possible = True, fitting can resume using a model file. \n",
        "resume_if_possible = True \n",
        "\n",
        "### Set resume_if_possible = False to force fitting from scratch.\n",
        "#resume_if_possible = False \n",
        "\n",
        "epochs = 100\n",
        "log_file_path = 'training_log.csv'\n",
        "model_file_path = 'model_epoch{epoch:06d}.hdf5'\n",
        "\n",
        "model_file_list = glob.glob('model_epoch*.hdf5')\n",
        "\n",
        "if resume_if_possible:\n",
        "  resume_flag = (len(model_file_list) >= 1) \n",
        "  \n",
        "if not resume_if_possible:\n",
        "  resume_flag = False\n",
        "  for f in model_file_list:\n",
        "    os.remove(f)\n",
        "\n",
        "if resume_flag:\n",
        "  latest_model_file = model_file_list[-1]\n",
        "  latest_epoch = int(latest_model_file[len('model_epoch'):-len('.hdf5')])\n",
        "  ## Load the saved model\n",
        "  model = keras.models.load_model(latest_model_file)\n",
        "\n",
        "  score = model.evaluate(test_images,test_labels, verbose=0)\n",
        "  print('Use {} to resume fitting. \\nTest loss: {}   Test accuracy: {}'.format(latest_model_file, score[0], score[1]))\n",
        "\n",
        "  if len(model_file_list) >= 2:\n",
        "    ## Delete all model files excpet the latest to save space\n",
        "    for f in model_file_list[:-1]:\n",
        "      os.remove(f)\n",
        "\n",
        "if not resume_flag:\n",
        "  latest_epoch = 0\n",
        "  ## Create a basic model instance\n",
        "  model = create_model()\n",
        "  os.remove(log_file_path)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "## Create checkpoint callback\n",
        "check_point_ = tf.keras.callbacks.ModelCheckpoint(filepath = model_file_path, \n",
        "                                                 monitor = 'val_acc',\n",
        "                                                 verbose=1,\n",
        "                                                 save_best_only = True,\n",
        "                                                 mode='auto',\n",
        "                                                 save_weights_only=False,\n",
        "                                                 period = 1)\n",
        "\n",
        "## Create early stopping callback\n",
        "early_stopping_ = tf.keras.callbacks.EarlyStopping(monitor='val_acc', \n",
        "                                                   min_delta=0, \n",
        "                                                   patience=3, \n",
        "                                                   verbose=1, \n",
        "                                                   mode='auto', \n",
        "                                                   baseline=None)\n",
        "\n",
        "## Create CSV logger callback\n",
        "csv_logger_ = tf.keras.callbacks.CSVLogger(filename = log_file_path, separator=',',\n",
        "                                           append = resume_flag)\n",
        "\n",
        "## Fit \n",
        "model.fit(train_images, train_labels, epochs = epochs, initial_epoch = latest_epoch,\n",
        "          validation_data = (test_images,test_labels),\n",
        "          callbacks = [check_point_, early_stopping_, csv_logger_])\n",
        "\n",
        "## Remove duplicates as save_best_only option of checkpoint is set to True.\n",
        "pd.options.display.max_rows = 8\n",
        "log_df = pd.read_csv(log_file_path)\n",
        "log_wo_dup_df = log_df.drop_duplicates(subset = ['epoch'], keep='last').reset_index(drop=True)\n",
        "display(log_wo_dup_df)\n",
        "log_wo_dup_df.to_csv((log_file_path[:-len('.csv')] + '_processed.csv'), index=False)\n",
        "\n",
        "print('\\nFiles in the working directoy:')\n",
        "display(os.listdir())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use model_epoch000018.hdf5 to resume fitting. \n",
            "Test loss: 0.41082902467250826   Test accuracy: 0.877\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1000 samples, validate on 1000 samples\n",
            "Epoch 19/100\n",
            " 768/1000 [======================>.......] - ETA: 0s - loss: 0.0096 - acc: 1.0000\n",
            "Epoch 00019: val_acc improved from -inf to 0.88000, saving model to model_epoch000019.hdf5\n",
            "1000/1000 [==============================] - 0s 436us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4233 - val_acc: 0.8800\n",
            "Epoch 20/100\n",
            " 800/1000 [=======================>......] - ETA: 0s - loss: 0.0084 - acc: 1.0000\n",
            "Epoch 00020: val_acc did not improve from 0.88000\n",
            "1000/1000 [==============================] - 0s 206us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4246 - val_acc: 0.8750\n",
            "Epoch 21/100\n",
            " 736/1000 [=====================>........] - ETA: 0s - loss: 0.0062 - acc: 1.0000\n",
            "Epoch 00021: val_acc did not improve from 0.88000\n",
            "1000/1000 [==============================] - 0s 211us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4304 - val_acc: 0.8770\n",
            "Epoch 22/100\n",
            " 800/1000 [=======================>......] - ETA: 0s - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 00022: val_acc did not improve from 0.88000\n",
            "1000/1000 [==============================] - 0s 204us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4269 - val_acc: 0.8770\n",
            "Epoch 00022: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>val_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.665</td>\n",
              "      <td>1.200675</td>\n",
              "      <td>0.787</td>\n",
              "      <td>0.721675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.879</td>\n",
              "      <td>0.415959</td>\n",
              "      <td>0.842</td>\n",
              "      <td>0.525714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.284789</td>\n",
              "      <td>0.853</td>\n",
              "      <td>0.469079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.952</td>\n",
              "      <td>0.217569</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.418832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.008906</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.423306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.008253</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.424606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.006871</td>\n",
              "      <td>0.877</td>\n",
              "      <td>0.430436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.006214</td>\n",
              "      <td>0.877</td>\n",
              "      <td>0.426869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    epoch    acc      loss  val_acc  val_loss\n",
              "0       0  0.665  1.200675    0.787  0.721675\n",
              "1       1  0.879  0.415959    0.842  0.525714\n",
              "2       2  0.925  0.284789    0.853  0.469079\n",
              "3       3  0.952  0.217569    0.878  0.418832\n",
              "..    ...    ...       ...      ...       ...\n",
              "18     18  1.000  0.008906    0.880  0.423306\n",
              "19     19  1.000  0.008253    0.875  0.424606\n",
              "20     20  1.000  0.006871    0.877  0.430436\n",
              "21     21  1.000  0.006214    0.877  0.426869\n",
              "\n",
              "[22 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Files in the working directoy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['keras_fit_with_callbacks_mnist.ipynb',\n",
              " 'training_log.csv',\n",
              " 'training_log_processed.csv',\n",
              " 'model_epoch000018.hdf5',\n",
              " 'model_epoch000019.hdf5']"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "K8zre0uERDU2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "\n",
        "https://keras.io/callbacks/\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint"
      ]
    }
  ]
}