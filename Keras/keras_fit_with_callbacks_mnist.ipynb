{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_fit_with_callbacks_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7F29nuHfiiUA",
        "colab_type": "code",
        "outputId": "7087848d-d5f1-4f83-b091-615be0897e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "### Set colaboratory True to run in Google Colaboratory. \n",
        "colab = True\n",
        "\n",
        "if colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  import os\n",
        "  ## Specify a directory in Google Drive\n",
        "  dir = '/content/drive/My Drive/Colab Notebooks/Save_Restore_Model'\n",
        "  os.chdir(dir)\n",
        "  #os.getcwd()\n",
        "  #os.listdir()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "As19XFC8jE-g",
        "colab_type": "code",
        "outputId": "484ef293-9f32-4339-914a-491ceeb0c195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "if colab:\n",
        "  ## Check the uptime. (Google Colab reboots every 12 hours)\n",
        "  !cat /proc/uptime | awk '{print \"Uptime is \" $1 /60 /60 \" hours (\" $1 \" sec)\"}'\n",
        "  ## Check the GPU info\n",
        "  !nvidia-smi\n",
        "  ## Check the Python version\n",
        "  !python --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uptime is 10.9064 hours (39263.12 sec)\n",
            "Fri Jan 25 09:41:01 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Python 3.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FMvSgQ5QjKYT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_restore_models.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "HZ219oTUjJXf",
        "colab_type": "code",
        "outputId": "6068b578-0e38-4c5e-d34e-591c169bbcac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "MpoVWvOdxUgf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set up data"
      ]
    },
    {
      "metadata": {
        "id": "65zkKSbQ3Jnc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_labels = train_labels[:1000]\n",
        "test_labels = test_labels[:1000]\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
        "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k8pNftRxLT1i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Returns a short sequential model\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    keras.layers.Dense(512, activation=tf.keras.activations.relu, input_shape=(784,)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
        "  ])\n",
        "  \n",
        "  model.compile(optimizer='adam', \n",
        "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrXvLv4kjx-v",
        "colab_type": "code",
        "outputId": "0046fe68-6aea-46ef-884a-0232eb3635c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        }
      },
      "cell_type": "code",
      "source": [
        "resume_if_possible = True\n",
        "#resume_if_possible = False\n",
        "\n",
        "epochs = 100\n",
        "log_file_path = 'training_log.csv'\n",
        "model_file_path = 'model_epoch{epoch:06d}.hdf5'\n",
        "\n",
        "model_file_list = glob.glob('model_epoch*.hdf5')\n",
        "\n",
        "if resume_if_possible:\n",
        "  resume_flag = (len(model_file_list) >= 1) \n",
        "  \n",
        "if not resume_if_possible:\n",
        "  resume_flag = False\n",
        "  for f in model_file_list:\n",
        "    os.remove(f)\n",
        "\n",
        "if resume_flag:\n",
        "  latest_model_file = model_file_list[-1]\n",
        "  latest_epoch = int(latest_model_file[len('model_epoch'):-len('.hdf5')])\n",
        "  ## Load the saved model\n",
        "  model = keras.models.load_model(latest_model_file)\n",
        "\n",
        "  score = model.evaluate(test_images,test_labels, verbose=0)\n",
        "  print('Use {} to resume fitting. \\nTest loss: {}   Test accuracy: {}'.format(latest_model_file, score[0], score[1]))\n",
        "\n",
        "  if len(model_file_list) >= 2:\n",
        "    ## Delete all model files excpet the latest to save space\n",
        "    for f in model_file_list[:-1]:\n",
        "      os.remove(f)\n",
        "\n",
        "if not resume_flag:\n",
        "  latest_epoch = 0\n",
        "  ## Create a basic model instance\n",
        "  model = create_model()\n",
        "  os.remove(log_file_path)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "## Create checkpoint callback\n",
        "check_point_ = tf.keras.callbacks.ModelCheckpoint(filepath = model_file_path, \n",
        "                                                 monitor = 'val_acc',\n",
        "                                                 verbose=1,\n",
        "                                                 save_best_only = True,\n",
        "                                                 mode='auto',\n",
        "                                                 save_weights_only=False,\n",
        "                                                 period = 1)\n",
        "\n",
        "## Create early stopping callback\n",
        "early_stopping_ = tf.keras.callbacks.EarlyStopping(monitor='val_acc', \n",
        "                                                   min_delta=0, \n",
        "                                                   patience=3, \n",
        "                                                   verbose=1, \n",
        "                                                   mode='auto', \n",
        "                                                   baseline=None)\n",
        "\n",
        "## Create CSV logger callback\n",
        "csv_logger_ = tf.keras.callbacks.CSVLogger(filename = log_file_path, separator=',',\n",
        "                                           append = resume_flag)\n",
        "\n",
        "## Fit \n",
        "model.fit(train_images, train_labels, epochs = epochs, initial_epoch = latest_epoch,\n",
        "          validation_data = (test_images,test_labels),\n",
        "          callbacks = [check_point_, early_stopping_, csv_logger_])\n",
        "\n",
        "pd.options.display.max_rows = 8\n",
        "log_df = pd.read_csv(log_file_path)\n",
        "log_wo_dup_df = log_df.drop_duplicates(subset = ['epoch'], keep='last').reset_index(drop=True)\n",
        "display(log_wo_dup_df)\n",
        "\n",
        "print('\\nFiles in the working directoy:')\n",
        "display(os.listdir())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use model_epoch000009.hdf5 to resume fitting. \n",
            "Test loss: 0.3914255723953247   Test accuracy: 0.875\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1000 samples, validate on 1000 samples\n",
            "Epoch 10/100\n",
            " 736/1000 [=====================>........] - ETA: 0s - loss: 0.0382 - acc: 0.9986\n",
            "Epoch 00010: val_acc improved from -inf to 0.87000, saving model to model_epoch000010.hdf5\n",
            "1000/1000 [==============================] - 0s 404us/step - loss: 0.0395 - acc: 0.9990 - val_loss: 0.3964 - val_acc: 0.8700\n",
            "Epoch 11/100\n",
            " 832/1000 [=======================>......] - ETA: 0s - loss: 0.0302 - acc: 1.0000\n",
            "Epoch 00011: val_acc improved from 0.87000 to 0.88000, saving model to model_epoch000011.hdf5\n",
            "1000/1000 [==============================] - 0s 247us/step - loss: 0.0307 - acc: 1.0000 - val_loss: 0.3967 - val_acc: 0.8800\n",
            "Epoch 12/100\n",
            " 736/1000 [=====================>........] - ETA: 0s - loss: 0.0248 - acc: 1.0000\n",
            "Epoch 00012: val_acc did not improve from 0.88000\n",
            "1000/1000 [==============================] - 0s 210us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.4044 - val_acc: 0.8690\n",
            "Epoch 13/100\n",
            " 800/1000 [=======================>......] - ETA: 0s - loss: 0.0229 - acc: 1.0000\n",
            "Epoch 00013: val_acc did not improve from 0.88000\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.4052 - val_acc: 0.8730\n",
            "Epoch 14/100\n",
            " 800/1000 [=======================>......] - ETA: 0s - loss: 0.0193 - acc: 1.0000\n",
            "Epoch 00014: val_acc did not improve from 0.88000\n",
            "1000/1000 [==============================] - 0s 204us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.4154 - val_acc: 0.8620\n",
            "Epoch 00014: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>val_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.653</td>\n",
              "      <td>1.196836</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.768876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.885</td>\n",
              "      <td>0.423072</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.535779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.929</td>\n",
              "      <td>0.275172</td>\n",
              "      <td>0.844</td>\n",
              "      <td>0.496816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.945</td>\n",
              "      <td>0.217269</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.443987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.030697</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.396725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.024527</td>\n",
              "      <td>0.869</td>\n",
              "      <td>0.404442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.021751</td>\n",
              "      <td>0.873</td>\n",
              "      <td>0.405173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.019279</td>\n",
              "      <td>0.862</td>\n",
              "      <td>0.415362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    epoch    acc      loss  val_acc  val_loss\n",
              "0       0  0.653  1.196836    0.749  0.768876\n",
              "1       1  0.885  0.423072    0.829  0.535779\n",
              "2       2  0.929  0.275172    0.844  0.496816\n",
              "3       3  0.945  0.217269    0.855  0.443987\n",
              "..    ...    ...       ...      ...       ...\n",
              "10     10  1.000  0.030697    0.880  0.396725\n",
              "11     11  1.000  0.024527    0.869  0.404442\n",
              "12     12  1.000  0.021751    0.873  0.405173\n",
              "13     13  1.000  0.019279    0.862  0.415362\n",
              "\n",
              "[14 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Files in the working directoy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['keras_fit_with_callbacks_mnist.ipynb',\n",
              " 'training_log.csv',\n",
              " 'model_epoch000009.hdf5',\n",
              " 'model_epoch000010.hdf5',\n",
              " 'model_epoch000011.hdf5']"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "K8zre0uERDU2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "\n",
        "https://keras.io/callbacks/\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint"
      ]
    },
    {
      "metadata": {
        "id": "q6CS8GB9WQeM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}